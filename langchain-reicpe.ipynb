{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae3f8936-82da-499b-aece-ab84ecb272c7",
   "metadata": {},
   "source": [
    "# Simple LangChain Index of Recipees to Vector DB.  \n",
    "\n",
    "Recipe data from : https://www.kaggle.com/datasets/pes12017000148/food-ingredients-and-recipe-dataset-with-images?rvi=1\n",
    "\n",
    "## Improt Environement Variables from File\n",
    "Need to have a .env file with OPENAI_API_KEY and a LANGSMITH_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91261279-dea6-4aba-a6ad-82c2b20f3dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from environs import Env\n",
    "import os\n",
    "import bs4\n",
    "from langchain import hub\n",
    "import csv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "env = Env()\n",
    "env.read_env(\"/Users/geoffreysmalling/development/langchain/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c4419-19a9-47e8-b1c8-d3f72a39f894",
   "metadata": {},
   "source": [
    "## connect to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ddffa-93d6-407c-a55a-460743e967e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key=env.str(\"OPENAI_API_KEY\"), model=\"gpt-3.5-turbo-0125\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = env.str(\"LANGSMITH_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2d5ff-24d8-4ad8-a0a2-2f8e891c76c8",
   "metadata": {},
   "source": [
    "## Test llm connection and get answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305cfb0f-b755-44f1-94c6-87d0e6e901a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"How do you prepare slamon sushi?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908836e2-2b4c-4d19-b744-b116d21c072c",
   "metadata": {},
   "source": [
    "# load, chuck, and index contents of the source\n",
    "use the CSV native Parser to parse file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d00df0-a19d-4edd-b92e-f326a60a7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# recipe_id is stored in column 0\n",
    "# title is stored in column 1\n",
    "# Instructions is stored in column 4\n",
    "# Cleaned_Ingredients is stored in column 5\n",
    "\n",
    "# loop through CSV file and create a text document containing\n",
    "# recipe_id, title, instructions, and cleaned ingredients\n",
    "# also concatenate title, instructions and cleaned ingredients into one document\n",
    "# and store in a list\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "recipes_docs = list()\n",
    "with open('/Users/geoffreysmalling/development/langchain/data/epicurious_recipe.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "            recipe_text = row[1] + \"\\n\\n \" + row[4] + \"\\n\\n\" + row[5]\n",
    "            source = \"epicurious - recipe title \" + row[1]\n",
    "            recipe = {\"id\": row[0], \"title\": row[1], \"instructions\": row[3], \"cleaned_ingredients\": row[5], \"recipe_text\": recipe_text, \"source\":source}\n",
    "            # build a langchain document for each recipe\n",
    "            recipe_doc = Document(page_content=recipe['recipe_text'], metadata = recipe )\n",
    "            recipes_docs.append(recipe_doc)  \n",
    "            line_count += 1\n",
    "print(f'Processed {line_count} lines.')\n",
    "print(\"type of docs object: \" + str(type(recipes_docs[0])))\n",
    "print(\"type of docs object: \" + str(recipes_docs[0]))\n",
    "print(\"number of docs: \" + str(len(recipes_docs)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd0ca8c-813c-4795-990a-c05a3c09c7ff",
   "metadata": {},
   "source": [
    "## split the docs into chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce6044-770d-4f26-97cf-44bf8fa1776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(recipes_docs)\n",
    "print(\"type of splits object: \" + str(type(splits)))\n",
    "print(\"number of splits: \" + str(len(splits)))\n",
    "print(\"metadata example: \" + str(splits[10].metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c41895f-a7f3-4f0c-bcba-e9bf1fad8405",
   "metadata": {},
   "source": [
    "## store in a vector store using openAI Embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32022b1f-e035-4f9f-8f38-66f11f857df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a02c79-90e9-4432-af4c-3932969a461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"type of vectorstore object: \" + str(type(vectorstore)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b3933-fe8b-4f7e-8aac-cfa6136279ee",
   "metadata": {},
   "source": [
    "## create a retriever and pull a prompt from the langsmith hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09be49b-303c-4ad9-8d5a-405a691edc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 30})\n",
    "retrieved_docs = retriever.invoke(\"what recipes contain garlic, rosemary, pepper and chicken\")\n",
    "print(len(retrieved_docs))\n",
    "print(retrieved_docs[2].page_content)\n",
    "print(retrieved_docs[3].metadata['source'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5576431-5453-4ccd-8a86-a7ccb5c250a3",
   "metadata": {},
   "source": [
    "## download a prompt for rag from the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78776e89-7c7f-4007-b915-c28c7ec35c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are a cooking assistant. You are to help people find recipes and prepare them. Use the following context to contrain your recipe knowledge for the query\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Take some time to think about the question and the context.\n",
    "\n",
    "If the user is asking for a recipe, give them instructions for the recipe in the following format:\n",
    "Ingredients: List the ingredients needed for this recipe\n",
    "\n",
    "If there are any preperation steps required, list that first as prep instrucitons.\n",
    "\n",
    "Prep Instructions: \n",
    "  estimate the prep time\n",
    "  list the steps to prepare the recipe.\n",
    "\n",
    "Instructions: \n",
    "    estimate the cook time\n",
    "    List the steps to cook this recipe. \n",
    "\n",
    "Cite the recipe you based your answer off of from the context.\n",
    "\n",
    "If the user is looking for general knowledge on a technique of cooking, explain the technique and list them sample recipes to try.\n",
    "\n",
    "Also, suggest some similar recipes to the user, in addition to the one you picked\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a509e-b9a9-44cf-8c69-07db5fe0d560",
   "metadata": {},
   "source": [
    "### create a method to break each chunk of docs into a new paragraph for the prompt context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840ec4e-06e9-43b5-82f9-387e904cd21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    context =  \"\\n\\n\".join(doc.page_content for doc in docs)    \n",
    "    return context\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d8679-4f3e-42de-b84e-96b7144e952c",
   "metadata": {},
   "source": [
    "## Build the LangChain\n",
    "- User the retriever to get context docs and then join them with format docs\n",
    "- Get the question to the llm via RunnablePassthrough\n",
    "- pass context and question to the prompt\n",
    "- pass prompt to llm\n",
    "- parse results to a string, vs a message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500bb19-9f39-466d-82c4-9542a2641189",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    #| StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e00076-3eee-4fa8-97ee-c687b7be5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke(\"What are ways to bbq or grill chicken?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f6bf0-a922-4487-af43-8ab1e1862d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2172a358-6da3-43d8-b158-557e4314b85b",
   "metadata": {},
   "source": [
    "## adding sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9834b5d-f5e2-41fd-9d07-5a91fc70273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "response = rag_chain_with_source.invoke(\"My kids do not like spicey food. My kids like simple food.  What can I make my kids with pasta and chicken?\")\n",
    "\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc090e6a-c496-4ad8-a643-fed5ae44166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### we can get the context and source from the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb381be-0136-40f4-97ca-bd43f3910f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['context'][1].metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700b1e3-7c13-4178-b9fb-880da22210ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80676912-bfe6-4d9a-b431-007a8ce588e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
