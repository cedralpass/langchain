{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae3f8936-82da-499b-aece-ab84ecb272c7",
   "metadata": {},
   "source": [
    "# Simple LangChain quickstart.  \n",
    "\n",
    "## Improt Environement Variables from File\n",
    "Need to have a .env file with OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91261279-dea6-4aba-a6ad-82c2b20f3dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from environs import Env\n",
    "env = Env()\n",
    "env.read_env(\"/Users/geoffreysmalling/development/langchain/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c4419-19a9-47e8-b1c8-d3f72a39f894",
   "metadata": {},
   "source": [
    "## connect to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ddffa-93d6-407c-a55a-460743e967e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(api_key=env.str(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2d5ff-24d8-4ad8-a0a2-2f8e891c76c8",
   "metadata": {},
   "source": [
    "## Test llm connection and get answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305cfb0f-b755-44f1-94c6-87d0e6e901a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509224f-7407-4bcb-9f1f-afec8b5aa563",
   "metadata": {},
   "source": [
    "## create a prompt\n",
    "use a ChatPromptTemplate to create a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d20f8b-9b6f-42c4-b735-7590d2095fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb60eb16-aa8b-4022-a243-b6e466432bf7",
   "metadata": {},
   "source": [
    "## chain the prompt to the llm\n",
    "execute the prompt then pass the results to the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a100f5-24f6-4d13-b37b-b37ae66d60a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm #chains the prompt operator and the llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443506fd-99ec-4f6d-9b3b-adde27bbce38",
   "metadata": {},
   "source": [
    "### Use the Chain of Prompt and LLM to invoke the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0579c536-3bb2-4aa6-863c-d48038846d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4622d3b-4233-4d14-bf63-c07f9b3ca1fd",
   "metadata": {},
   "source": [
    "### LLM responds by default in a Message format object.  \n",
    "Simply parse the message into a string with LangChain parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da1082-928c-44fc-9707-3017a70c3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a3a4b-6a9c-4fc0-bcca-9535b4cea4b0",
   "metadata": {},
   "source": [
    "## Scrape websits to get content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf53a8e4-9bea-4f1c-9402-d361af5c7876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6fec86-2e41-4c56-bf8f-b7abb443dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(docs))\n",
    "print(docs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f784d9d1-e1ee-4aeb-802b-1a3b92ebccd3",
   "metadata": {},
   "source": [
    "## Use Embeddings to create vecotrs for searching against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539ea0f-f9b4-42f0-ad72-81a52682cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf85eb2-22f9-43e2-8e5f-d258bf059add",
   "metadata": {},
   "source": [
    "## Store embeddings into Vector Store\n",
    "Using FAISS (Facebook AI Similarity Search) a simple in memory vector store\n",
    "first we split the documents\n",
    "then usting the set of documents and the openai embeddings api we calculate a vector db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31510b06-9c51-4063-8fd3-7ee4dd4b48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "print(type(documents))\n",
    "print(len(docs))\n",
    "print(len(documents))\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f351d-3133-4138-a393-3ba2ac473068",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aad843-be27-481c-89de-33eabcd422e6",
   "metadata": {},
   "source": [
    "## Search the vector store using similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166c034-457e-4175-9999-63f22e8b19f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_docs = vector.similarity_search('monitoring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f8921-a6c9-44ed-b691-891348686117",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f0937-abba-4f29-b834-56272a526983",
   "metadata": {},
   "source": [
    "# create a new prompt with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3202121e-fcee-4e91-bc7a-3aff7822b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae0c30e-f487-45a6-8ca2-1e7917d58f84",
   "metadata": {},
   "source": [
    "# using a retriever\n",
    "Langchain abstracts the retrieval process using a retrieval chain\n",
    "pass in a retriever using the vector store\n",
    "and the document chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e19daa-65c9-41fb-9273-9f61f274ec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d14a5-08f4-46af-9795-c0c7d9987f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9611d04-017d-42f9-bd4d-645bfe416d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a621abdc-35b9-4f8d-a39e-1b2e85e776ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8271f9-fffc-4ac3-9109-8503b168a5c1",
   "metadata": {},
   "source": [
    "### we can attrbute the source by traversing to the metadata object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e70f5ce-4f4d-4e75-8693-e238b033aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['context'][0].metadata['source'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
